{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForQuestionAnswering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205efb339f5d4cf5a1b0df3cc183c4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub\\models--bert-large-uncased-whole-word-masking-finetuned-squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740429b4248e4cbab6205679dbcfd9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbb9a55abc341609d4979e6f7c962b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de55c0bbeea49cfaae89e20f2f23005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wiki_article.txt\", \"r\", encoding = 'utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_document = \"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding error as token length exceeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = tokenizer.encode(text, add_special_tokens = True, return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking text into parts and then combining the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_chunk_len = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [text[i:i + max_chunk_len] for i in range(0, len(text), max_chunk_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Saturn V was a rocket NASA built to send people to the moon. (The V in the name is the Roman numeral five.) The Saturn V was a type of rocket called a Heavy Lift Vehicle. That means it was very powerful. It was the most powerful rocket that had ever flown successfully. The Saturn V was used in the Apollo program in the 1960s and 1970s. It also was used to launch the Skylab space station.\\n\\nThe Saturn V rocket was 111 meters (363 feet) tall, about the height of a 36-story-tall building, and 18 meters (60 ',\n",
       " 'feet) taller than the Statue of Liberty. Fully fueled for liftoff, the Saturn V weighed 2.8 million kilograms (6.2 million pounds), the weight of about 400 elephants. The rocket generated 34.5 million newtons (7.6 million pounds) of thrust at launch, creating more power than 85 Hoover Dams. A car that gets 48 kilometers (30 miles) to the gallon could drive around the world around 800 times with the amount of fuel the Saturn V used for a lunar landing mission. It could launch about 118,000 kilograms (130 ton',\n",
       " 's) into Earth orbit. That’s about as much weight as 10 school buses. The Saturn V could launch about 43,500 kilograms (50 tons) to the moon. That’s about the same as four school buses.\\n\\nThe Saturn V was developed at NASA’s Marshall Space Flight Center in Huntsville, Ala. It was one of three types of Saturn rockets NASA built. Two smaller rockets, the Saturn I (1) and IB (1b), were used to launch humans into Earth orbit. The Saturn V sent them beyond Earth orbit to the moon. The first Saturn V was launched i',\n",
       " 'n 1967. It was called Apollo 4. Apollo 6 followed in 1968. Both of these rockets were launched without crews. These launches tested the Saturn V rocket.\\n\\nThe first Saturn V launched with a crew was Apollo 8. On this mission, astronauts orbited the moon but did not land. On Apollo 9, the crew tested the Apollo moon lander by flying it in Earth orbit without landing. On Apollo 10, the Saturn V launched the lunar lander to the moon. The crew tested the lander in space but did not land it on the moon. In 1969, ',\n",
       " 'Apollo 11 was the first mission to land astronauts on the moon. Saturn V rockets also made it possible for astronauts to land on the moon on Apollo 12, 14, 15, 16 and 17. On Apollo 13, the Saturn V lifted the crew into space, but a problem prevented them from being able to land on the moon. That problem was not with the Saturn V, but with the Apollo spacecraft. The last Saturn V was launched in 1973, without a crew. It was used to launch the Skylab space station into Earth orbit.\\n\\nThe Saturn V that launched',\n",
       " ' the Skylab space station only had two stages. The Saturn V rockets used for the Apollo missions had three stages. Each stage would burn its engines until it was out of fuel and would then separate from the rocket. The engines on the next stage would fire, and the rocket would continue into space. The first stage had the most powerful engines, since it had the challenging task of lifting the fully fueled rocket off the ground. The first stage lifted the rocket to an altitude of about 68 kilometers (42 miles',\n",
       " '). The second stage carried it from there almost into orbit. The third stage placed the Apollo spacecraft into Earth orbit and pushed it toward the moon. The first two stages fell into the ocean after separation. The third stage either stayed in space or hit the moon.\\n\\n\\n\\n']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RuntimeError: The size of tensor a (122) must match the size of tensor b (8) at non-singleton dimension 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chunk in chunks:\n",
    "#     input_ids = tokenizer.encode(chunk, add_special_tokens=True, return_tensors='pt')\n",
    "\n",
    "#     question = \"What is the length of Saturn V?\"\n",
    "#     input_ids_question = tokenizer.encode(question, add_special_tokens=False, return_tensors='pt')\n",
    "\n",
    "#     start_scores, end_scores = model(input_ids, input_ids_question)\n",
    "#     answer_start = torch.argmax(start_scores)\n",
    "#     answer_end = torch.argmax(end_scores)\n",
    "\n",
    "#     answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end+1]))\n",
    "#     answers.append(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TypeError: argmax(): argument 'input' (position 1) must be Tensor, not str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chunk in chunks:\n",
    "#     # Tokenize the chunk\n",
    "#     tokenized_chunk = tokenizer.encode_plus(chunk, add_special_tokens=True, return_tensors='pt', max_length=max_chunk_len, truncation=True)\n",
    "#     input_ids_chunk = tokenized_chunk['input_ids']\n",
    "#     token_type_ids_chunk = tokenized_chunk['token_type_ids']\n",
    "#     attention_mask_chunk = tokenized_chunk['attention_mask']\n",
    "\n",
    "#     # Run question answering\n",
    "#     question = \"What is the length of Saturn V?\"\n",
    "#     input_ids_question = tokenizer.encode(question, add_special_tokens=False, return_tensors='pt')\n",
    "\n",
    "#     start_scores, end_scores = model(input_ids_chunk, token_type_ids=token_type_ids_chunk, attention_mask=attention_mask_chunk, start_positions=None, end_positions=None, inputs_embeds=None)\n",
    "    \n",
    "#     answer_start = torch.argmax(start_scores)\n",
    "#     answer_end = torch.argmax(end_scores)\n",
    "    \n",
    "#     # Get the answer tokens\n",
    "#     answer_tokens = input_ids_chunk[0][answer_start:answer_end+1]\n",
    "#     answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "    \n",
    "#     answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in chunks:\n",
    "    # Tokenize the chunk\n",
    "    tokenized_chunk = tokenizer.encode_plus(chunk, add_special_tokens=True, return_tensors='pt', max_length=max_chunk_len, truncation=True)\n",
    "    input_ids_chunk = tokenized_chunk['input_ids']\n",
    "    token_type_ids_chunk = tokenized_chunk['token_type_ids']\n",
    "    attention_mask_chunk = tokenized_chunk['attention_mask']\n",
    "\n",
    "    # Run question answering\n",
    "    question = \"What is the length of Saturn V?\"\n",
    "    input_ids_question = tokenizer.encode(question, add_special_tokens=False, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        outputs = model(input_ids_chunk, token_type_ids=token_type_ids_chunk, attention_mask=attention_mask_chunk)\n",
    "        start_scores = outputs.start_logits\n",
    "        end_scores = outputs.end_logits\n",
    "\n",
    "    # Ensure tensors are on CPU for argmax\n",
    "    start_scores = start_scores.cpu()\n",
    "    end_scores = end_scores.cpu()\n",
    "\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "\n",
    "    # Get the answer tokens\n",
    "    answer_tokens = input_ids_chunk[0][answer_start:answer_end+1]\n",
    "    answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "    answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOSS, the answer is ready!\n"
     ]
    }
   ],
   "source": [
    "combined_answer = \" \".join(answers)\n",
    "print(\"BOSS, the answer is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the length of Saturn V?\n",
      "Combined Answer: the saturn v was a rocket nasa built to send people to the moon. ( the v in the name is the roman numeral five. ) the saturn v was a type of rocket called a heavy lift vehicle  43, 500 kilograms apollo 6 apollo 11  third stage placed the apollo spacecraft into earth orbit and pushed it toward the moon\n"
     ]
    }
   ],
   "source": [
    "print(\"Question:\", question)\n",
    "print(\"Combined Answer:\", combined_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_text = tokenizer.tokenize(text_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = [tokenizer.cls_token_id] + input_ids + [tokenizer.sep_token_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RAW BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting evaluation mode\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"What is the question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids_question = tokenizer.encode(question, add_special_tokens = False, return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the start and end scores for each token\n",
    "# start_scores, end_scores = model(input_ids, input_ids_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find tokens with max match\n",
    "# answer_start = torch.argmax(start_scores)\n",
    "# answer_end = torch.argmax(end_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COmbine tokens into final answer\n",
    "# answer = ' '.join(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start:answer_end+1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
